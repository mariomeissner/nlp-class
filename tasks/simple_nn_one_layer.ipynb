{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_nn_one_layer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariomeissner/nlp_class/blob/master/simple_nn_one_layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4Zv1v40uphb-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import necessary packages\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.utils import shuffle\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wCIzSHoOphcK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data = datasets.load_iris()\n",
        "X, y = data.data, data.target\n",
        "X, y = shuffle(X, np.expand_dims(y, axis=1), random_state=1)\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vrVIIbPwe-T6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Normalize input data\n",
        "X -= X.mean(axis=0)\n",
        "X /= X.max(axis=0)\n",
        "print(X.max(axis=0), X.mean(axis=0).round(2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ICEZQAa0phcU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Explore the data\n",
        "print(np.concatenate([X, y], axis=1).round(2)[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ra5Ob8zTphc9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Merge classes 1 and 2\n",
        "y = y.reshape((len(y),1))\n",
        "y = np.where(y==2, 1, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wJWkNhQbphcy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get the data shapes\n",
        "batch, features = X.shape\n",
        "output = 1\n",
        "print(f\"Shapes: \\nbatch: {batch}, features: {features}, output: {output}.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TBdWMzPZphcn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Our activation function\n",
        "def sigmoid(x, deriv = False):\n",
        "  ''' The sigmoid of x. \n",
        "  If deriv = True, then x is the output of a previous sigmoid call. '''\n",
        "  if deriv: return x * (1 - x)\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eul1TDfxynt2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(y, pred):\n",
        "  ''' Computes the accuracy of the predictions pred with respect to y. '''\n",
        "  count = 0\n",
        "  for y_r,pred_r in zip(y,pred):\n",
        "    if y_r.argmax() == pred_r.argmax():\n",
        "      count += 1\n",
        "  return count / len(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cCyZdDISg8z2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize weights\n",
        "w1 = np.random.normal(size=(features, output)) # (4,1)\n",
        "b1 = np.random.normal(size=(1, output)) # (1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4rFAA1z7phdF",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for i in range(1000):\n",
        "\n",
        "    # forward pass\n",
        "    zpred = X.dot(w1) + b1 # (batch,features) @ (features,output) + (1,output)\n",
        "    pred = sigmoid(zpred)\n",
        "    \n",
        "    # loss (squared error)\n",
        "    loss = np.sum(np.square((pred - y)))\n",
        "    \n",
        "    # Print loss every now and then\n",
        "    if i % 50 == 0:\n",
        "        print(f\"Iteration {i:0>3}, loss: {loss:6.3f}\")\n",
        "    \n",
        "    # backpropagation\n",
        "    # shapes of grad variables should match originals!\n",
        "    grad_pred = 2.0 * (pred - y)\n",
        "    grad_zpred = grad_pred * sigmoid(pred, deriv=True)\n",
        "    grad_w1 = X.T.dot(grad_zpred)\n",
        "    grad_b1 = grad_zpred.sum(axis=0)\n",
        "    \n",
        "    # update weights\n",
        "    w1 -= 1e-3 * grad_w1\n",
        "    b1 -= 1e-3 * grad_b1\n",
        "    \n",
        "# View a slice of the predictions\n",
        "print(\"\\nPredictions:\")\n",
        "print(np.concatenate((pred, y), axis=1).round(2)[:10])\n",
        "print(f\"\\nAccuracy: {accuracy(y, pred)}.\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}